{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Speech Decoding on Google Colab\n",
    "\n",
    "**Requirements:** Colab Pro (for 24hr sessions + better GPU)\n",
    "\n",
    "**Total Time:** ~16 hours (6hrs Stage 1 + 10hrs Stage 2 on A100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo into /content\n",
    "%cd /content\n",
    "!git clone https://github.com/flinkerlab/neural_speech_decoding.git\n",
    "\n",
    "# Enter the repo - this is our workspace\n",
    "%cd neural_speech_decoding\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Mount Google Drive & Setup Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create persistent storage in Google Drive\n",
    "!mkdir -p /content/drive/MyDrive/nsd_data\n",
    "!mkdir -p /content/drive/MyDrive/nsd_outputs\n",
    "\n",
    "# Link them to the repo workspace\n",
    "!mkdir -p example_data\n",
    "!ln -s /content/drive/MyDrive/nsd_data example_data/data\n",
    "!ln -s /content/drive/MyDrive/nsd_outputs output\n",
    "\n",
    "print(\"✓ Google Drive mounted and linked\")\n",
    "print(f\"  Data: example_data/data -> Google Drive\")\n",
    "print(f\"  Output: output -> Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Upload Data to Google Drive\n",
    "\n",
    "**Before running training, you need to:**\n",
    "\n",
    "1. Download HB02 dataset from: https://data.mendeley.com/datasets/fp4bv9gtwk/2\n",
    "2. Upload the files to: **MyDrive/nsd_data/** in your Google Drive\n",
    "3. Verify they're there by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is present\n",
    "!ls -lh /content/drive/MyDrive/nsd_data/\n",
    "\n",
    "# Should see HB02 data files (*.hdf5 or *.h5)\n",
    "print(\"\\nIf empty, please upload HB02 data to: MyDrive/nsd_data/ in Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Update Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Update data path in config\n",
    "with open('configs/AllSubjectInfo.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config['Shared']['RootPath'] = './example_data/data/'\n",
    "\n",
    "with open('configs/AllSubjectInfo.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"✓ Config updated: RootPath = {config['Shared']['RootPath']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Stage 1 - Audio-to-Audio Training (a2a)\n",
    "\n",
    "**Time:** ~6 hours on A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_a2a.py \\\n",
    "  --OUTPUT_DIR output/a2a/HB02 \\\n",
    "  --trainsubject HB02 \\\n",
    "  --testsubject HB02 \\\n",
    "  --param_file configs/a2a_production.yaml \\\n",
    "  --batch_size 16 \\\n",
    "  --reshape 1 \\\n",
    "  --DENSITY \"HB\" \\\n",
    "  --wavebased 1 \\\n",
    "  --n_filter_samples 80 \\\n",
    "  --n_fft 256 \\\n",
    "  --formant_supervision 1 \\\n",
    "  --intensity_thres -1 \\\n",
    "  --epoch_num 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Stage 1 completed\n",
    "!ls output/a2a/HB02/*.pth | wc -l\n",
    "print(\"Expected: 60 checkpoint files (model_epoch0.pth to model_epoch59.pth)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Stage 2 - ECoG-to-Audio Training (e2a)\n",
    "\n",
    "**Time:** ~10 hours on A100\n",
    "\n",
    "**This produces the weights you need for phoneme classification!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_e2a.py \\\n",
    "  --OUTPUT_DIR output/e2a/resnet_HB02 \\\n",
    "  --trainsubject HB02 \\\n",
    "  --testsubject HB02 \\\n",
    "  --param_file configs/e2a_production.yaml \\\n",
    "  --batch_size 16 \\\n",
    "  --MAPPING_FROM_ECOG ECoGMapping_ResNet \\\n",
    "  --reshape 1 \\\n",
    "  --DENSITY \"HB\" \\\n",
    "  --wavebased 1 \\\n",
    "  --dynamicfiltershape 0 \\\n",
    "  --n_filter_samples 80 \\\n",
    "  --n_fft 256 \\\n",
    "  --formant_supervision 1 \\\n",
    "  --intensity_thres -1 \\\n",
    "  --epoch_num 60 \\\n",
    "  --pretrained_model_dir output/a2a/HB02 \\\n",
    "  --causal 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Stage 2 completed\n",
    "!ls output/e2a/resnet_HB02/*.pth | wc -l\n",
    "!ls -lh output/e2a/resnet_HB02/model_epoch59.pth\n",
    "\n",
    "print(\"\\n✓✓✓ TRAINING COMPLETE ✓✓✓\")\n",
    "print(\"\\nYour pretrained weights:\")\n",
    "print(\"  output/e2a/resnet_HB02/model_epoch59.pth\")\n",
    "print(\"\\nAlso saved to Google Drive:\")\n",
    "print(\"  /content/drive/MyDrive/nsd_outputs/e2a/resnet_HB02/model_epoch59.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Download Weights (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Uncomment to download the final checkpoint to your computer:\n",
    "# files.download('output/e2a/resnet_HB02/model_epoch59.pth')\n",
    "\n",
    "print(\"Weights are in Google Drive at: MyDrive/nsd_outputs/e2a/resnet_HB02/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Use for Phoneme Classification\n",
    "\n",
    "Update your `ecog_decoder_finetune.ipynb` with:\n",
    "\n",
    "```python\n",
    "checkpoint_path = \"output/e2a/resnet_HB02/model_epoch59.pth\"\n",
    "# Or from Google Drive:\n",
    "# checkpoint_path = \"/content/drive/MyDrive/nsd_outputs/e2a/resnet_HB02/model_epoch59.pth\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
