{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNCUMClVMAl2"
      },
      "source": [
        "# Train Neural Speech Decoding on Google Colab\n",
        "\n",
        "**Requirements:** Colab Pro (for 24hr sessions + better GPU)\n",
        "\n",
        "**Total Time:** ~16 hours (6hrs Stage 1 + 10hrs Stage 2 on A100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Push Code"
      ],
      "metadata": {
        "id": "3Hq9suwSRkYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git add colab_training.ipynb\n",
        "!git commit -m \"update notebook\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGBxAX5HSlPc",
        "outputId": "023f8940-2fd8-4ee8-d573-563799ec313a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"update\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfPqyYWrRy4i",
        "outputId": "b98c8eea-26ce-46f8-a728-3d09427699c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main --rebase\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw0SZ8IaS4Wr",
        "outputId": "230722bd-28b0-47eb-f150-e15b8a475091"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/atomiiw/neural_speech_decoding\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"maidouatomwang@gmail.com\"\n",
        "!git config --global user.name \"atomiiw\"\n",
        "!git remote set-url origin https://atomiiw:<TOKEN>@github.com/atomiiw/neural_speech_decoding.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07E6pO5KRoNt",
        "outputId": "4143622f-4004-46ae-ea59-010173f196e8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: TOKEN: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yai__P_TMAl2"
      },
      "source": [
        "## Step 1: Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAhHEVltMAl2",
        "outputId": "2e699055-0bea-4097-e4c3-51eb6fc90781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov  7 02:41:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxXMr4aMAl3"
      },
      "source": [
        "## Step 2: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7H7T8_YMAl3",
        "outputId": "1168a968-c8c5-44cc-93f5-9ba438b39482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'neural_speech_decoding' already exists and is not an empty directory.\n",
            "/content/neural_speech_decoding\n",
            "/content/neural_speech_decoding\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo into /content\n",
        "%cd /content\n",
        "!git clone https://github.com/flinkerlab/neural_speech_decoding.git\n",
        "\n",
        "# Enter the repo - this is our workspace\n",
        "%cd neural_speech_decoding\n",
        "\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%cd neural_speech_decoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8OLyaYmiSpe",
        "outputId": "251544f2-7d69-4f80-8ff2-0fac3868d82c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/neural_speech_decoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPw1xRzQMAl3"
      },
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yacs h5py librosa scipy soundfile pesq pystoi tqdm matplotlib seaborn -q"
      ],
      "metadata": {
        "id": "j6gRKLBrMYhS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHPENoCQMAl3"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch 2.2+ which supports Python 3.12\n",
        "!pip install torch==2.2.0+cu118 torchvision==0.17.0+cu118 torchaudio==2.2.0+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install yacs h5py librosa scipy soundfile pesq pystoi tqdm matplotlib seaborn -q\n",
        "\n",
        "# Verify installation\n",
        "import torch\n",
        "import sys\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Python: {sys.version}\")"
      ],
      "metadata": {
        "id": "Pb4Hfznhmvwb",
        "outputId": "35f1cc24-7b9a-49fb-d238-b758fa69b7d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch==2.2.0+cu118 in /usr/local/lib/python3.12/dist-packages (2.2.0+cu118)\n",
            "Requirement already satisfied: torchvision==0.17.0+cu118 in /usr/local/lib/python3.12/dist-packages (0.17.0+cu118)\n",
            "Requirement already satisfied: torchaudio==2.2.0+cu118 in /usr/local/lib/python3.12/dist-packages (2.2.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0+cu118) (11.8.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.0+cu118) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.0+cu118) (2.32.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.0+cu118) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.0+cu118) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0+cu118) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0+cu118) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0+cu118) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0+cu118) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.0+cu118) (1.3.0)\n",
            "PyTorch: 2.2.0+cu118\n",
            "CUDA available: True\n",
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4nOPRDUMAl3"
      },
      "source": [
        "## Step 4: Mount Google Drive & Setup Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qulz_1fLMAl3",
        "outputId": "a990c857-c6a9-42a4-c3cd-23e296284129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted and linked\n",
            "  Data: example_data/data -> Google Drive\n",
            "  Output: output -> Google Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create persistent storage in Google Drive\n",
        "!mkdir -p /content/drive/MyDrive/nsd_data\n",
        "!mkdir -p /content/drive/MyDrive/nsd_outputs\n",
        "\n",
        "# Link them to the repo workspace\n",
        "!mkdir -p example_data\n",
        "!ln -s /content/drive/MyDrive/nsd_data example_data/data\n",
        "!ln -s /content/drive/MyDrive/nsd_outputs output\n",
        "\n",
        "print(\"✓ Google Drive mounted and linked\")\n",
        "print(f\"  Data: example_data/data -> Google Drive\")\n",
        "print(f\"  Output: output -> Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQp3th7PMAl3"
      },
      "source": [
        "## Step 5: Upload Data to Google Drive\n",
        "\n",
        "**Before running training, you need to:**\n",
        "\n",
        "1. Download HB02 dataset from: https://data.mendeley.com/datasets/fp4bv9gtwk/2\n",
        "2. Upload the files to: **MyDrive/nsd_data/** in your Google Drive\n",
        "3. Verify they're there by running the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmkXvLxjMAl3",
        "outputId": "9cd1cb06-a826-4126-edbc-24a6c915a91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw------- 1 root root 1.1G Nov  7 03:11 HB02.h5\n",
            "\n",
            "If empty, please upload HB02 data to: MyDrive/nsd_data/ in Google Drive\n"
          ]
        }
      ],
      "source": [
        "# Check if data is present\n",
        "!ls -lh /content/drive/MyDrive/nsd_data/\n",
        "\n",
        "# Should see HB02 data files (*.hdf5 or *.h5)\n",
        "print(\"\\nIf empty, please upload HB02 data to: MyDrive/nsd_data/ in Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4MzeDuMAl3"
      },
      "source": [
        "## Step 6: Update Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kB1hxvmMAl3",
        "outputId": "8f4d9e43-81be-42b5-cbd7-704433f83ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Config updated: RootPath = ./example_data/data/\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Update data path in config\n",
        "with open('configs/AllSubjectInfo.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "config['Shared']['RootPath'] = './example_data/data/'\n",
        "\n",
        "with open('configs/AllSubjectInfo.json', 'w') as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "\n",
        "print(f\"✓ Config updated: RootPath = {config['Shared']['RootPath']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRy8us5xMAl3"
      },
      "source": [
        "## Step 7: Stage 1 - Audio-to-Audio Training (a2a)\n",
        "\n",
        "**Time:** ~6 hours on A100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWpZzLjRMAl3",
        "outputId": "6a2c7191-790e-4136-a379-055a5c938699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/neural_speech_decoding/train_a2a.py\", line 17, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 1471, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "['HB02']\n",
            "rank in _run 0\n",
            "2025-11-07 04:41:39,447 logger INFO: Namespace(config_file='configs/a2a_production.yaml', opts=[], subject='NYxxx', trainsubject='HB02', testsubject='HB02', DENSITY='HB', OUTPUT_DIR='output/a2a/HB02', wavebased=1, bgnoise_fromdata=1, ignore_loading=0, finetune=0, learnedmask=0, dynamicfiltershape=0, formant_supervision=1, pitch_supervision=0, intensity_supervision=0, n_filter_samples=80, n_fft=256, reverse_order=1, lar_cap=0, intensity_thres=-1.0, unified=0, ONEDCONFIRST=1, RNN_TYPE='LSTM', RNN_LAYERS=1, RNN_COMPUTE_DB_LOUDNESS=1, BIDIRECTION=1, MAPPING_FROM_ECOG='ECoGMappingBottleneck_ran', COMPONENTKEY='', old_formant_file=0, reshape=1, fastattentype='full', phone_weight=0, ld_loss_weight=1, alpha_loss_weight=1, consonant_loss_weight=0, amp_formant_loss_weight=0, component_regression=0, freq_single_formant_loss_weight=0, amp_minmax=0, amp_energy=0, f0_midi=0, alpha_db=0, network_db=0, delta_time=0, delta_freq=0, cumsum=0, distill=0, noise_db=-50, classic_pe=0, temporal_down_before=0, classic_attention=1, batch_size=16, param_file='configs/a2a_production.yaml', pretrained_model_dir='', causal=0, anticausal=0, rdropout=0, epoch_num=60, use_stoi=0, use_denoise=0)\n",
            "2025-11-07 04:41:39,447 logger INFO: World size: 1\n",
            "2025-11-07 04:41:39,447 logger INFO: Loaded configuration file configs/a2a_production.yaml\n",
            "Running on  NVIDIA A100-SXM4-40GB\n",
            "within train function 256\n",
            "patient in model HB02\n",
            "encoder loudness, 256\n",
            "self.noise_db,self.max_db -50 22.5\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/neural_speech_decoding/train_a2a.py\", line 940, in <module>\n",
            "    run(\n",
            "  File \"/content/neural_speech_decoding/utils/launcher.py\", line 174, in run\n",
            "    _run(0, world_size, fn, defaults, write_log, no_cuda, args_)\n",
            "  File \"/content/neural_speech_decoding/utils/launcher.py\", line 158, in _run\n",
            "    fn(**matching_args_)\n",
            "  File \"/content/neural_speech_decoding/train_a2a.py\", line 288, in train\n",
            "    model = Model(\n",
            "            ^^^^^^\n",
            "  File \"/content/neural_speech_decoding/model.py\", line 382, in __init__\n",
            "    self.stoi_loss_female = STOI_Loss(extended=False, plus=True, FFT_size=256)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/neural_speech_decoding/model.py\", line 178, in __init__\n",
            "    self.loss_func = NegSTOILoss(\n",
            "                     ^^^^^^^^^^^^\n",
            "  File \"/content/neural_speech_decoding/metrics/torch_stoi.py\", line 88, in __init__\n",
            "    win = torch.from_numpy(np.hanning(self.win_len + 2)[1:-1]).float()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Numpy is not available\n"
          ]
        }
      ],
      "source": [
        "!python train_a2a.py \\\n",
        "  --OUTPUT_DIR output/a2a/HB02 \\\n",
        "  --trainsubject HB02 \\\n",
        "  --testsubject HB02 \\\n",
        "  --param_file configs/a2a_production.yaml \\\n",
        "  --batch_size 16 \\\n",
        "  --reshape 1 \\\n",
        "  --DENSITY \"HB\" \\\n",
        "  --wavebased 1 \\\n",
        "  --n_filter_samples 80 \\\n",
        "  --n_fft 256 \\\n",
        "  --formant_supervision 1 \\\n",
        "  --intensity_thres -1 \\\n",
        "  --epoch_num 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6izAitkqMAl3"
      },
      "outputs": [],
      "source": [
        "# Check Stage 1 completed\n",
        "!ls output/a2a/HB02/*.pth | wc -l\n",
        "print(\"Expected: 60 checkpoint files (model_epoch0.pth to model_epoch59.pth)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuNpS19mMAl3"
      },
      "source": [
        "## Step 8: Stage 2 - ECoG-to-Audio Training (e2a)\n",
        "\n",
        "**Time:** ~10 hours on A100\n",
        "\n",
        "**This produces the weights you need for phoneme classification!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjdpF4fnMAl3"
      },
      "outputs": [],
      "source": [
        "!python train_e2a.py \\\n",
        "  --OUTPUT_DIR output/e2a/resnet_HB02 \\\n",
        "  --trainsubject HB02 \\\n",
        "  --testsubject HB02 \\\n",
        "  --param_file configs/e2a_production.yaml \\\n",
        "  --batch_size 16 \\\n",
        "  --MAPPING_FROM_ECOG ECoGMapping_ResNet \\\n",
        "  --reshape 1 \\\n",
        "  --DENSITY \"HB\" \\\n",
        "  --wavebased 1 \\\n",
        "  --dynamicfiltershape 0 \\\n",
        "  --n_filter_samples 80 \\\n",
        "  --n_fft 256 \\\n",
        "  --formant_supervision 1 \\\n",
        "  --intensity_thres -1 \\\n",
        "  --epoch_num 60 \\\n",
        "  --pretrained_model_dir output/a2a/HB02 \\\n",
        "  --causal 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G906_Q6WMAl4"
      },
      "outputs": [],
      "source": [
        "# Check Stage 2 completed\n",
        "!ls output/e2a/resnet_HB02/*.pth | wc -l\n",
        "!ls -lh output/e2a/resnet_HB02/model_epoch59.pth\n",
        "\n",
        "print(\"\\n✓✓✓ TRAINING COMPLETE ✓✓✓\")\n",
        "print(\"\\nYour pretrained weights:\")\n",
        "print(\"  output/e2a/resnet_HB02/model_epoch59.pth\")\n",
        "print(\"\\nAlso saved to Google Drive:\")\n",
        "print(\"  /content/drive/MyDrive/nsd_outputs/e2a/resnet_HB02/model_epoch59.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT6ahMQtMAl4"
      },
      "source": [
        "## Step 9: Download Weights (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6x1SvlNMAl4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Uncomment to download the final checkpoint to your computer:\n",
        "# files.download('output/e2a/resnet_HB02/model_epoch59.pth')\n",
        "\n",
        "print(\"Weights are in Google Drive at: MyDrive/nsd_outputs/e2a/resnet_HB02/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Ewd032MAl4"
      },
      "source": [
        "## Next Steps: Use for Phoneme Classification\n",
        "\n",
        "Update your `ecog_decoder_finetune.ipynb` with:\n",
        "\n",
        "```python\n",
        "checkpoint_path = \"output/e2a/resnet_HB02/model_epoch59.pth\"\n",
        "# Or from Google Drive:\n",
        "# checkpoint_path = \"/content/drive/MyDrive/nsd_outputs/e2a/resnet_HB02/model_epoch59.pth\"\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}