{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNCUMClVMAl2"
      },
      "source": [
        "# Train Neural Speech Decoding on Google Colab\n",
        "\n",
        "**Requirements:** Colab Pro (for 24hr sessions + better GPU)\n",
        "\n",
        "**Total Time:** ~16 hours (6hrs Stage 1 + 10hrs Stage 2 on A100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Push Code"
      ],
      "metadata": {
        "id": "3Hq9suwSRkYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git add colab_training.ipynb\n",
        "!git commit -m \"update notebook\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGBxAX5HSlPc",
        "outputId": "023f8940-2fd8-4ee8-d573-563799ec313a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"update\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfPqyYWrRy4i",
        "outputId": "92035264-c193-425b-8494-630619337ef4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main --rebase\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "xw0SZ8IaS4Wr",
        "outputId": "4ec3171c-c1f2-4696-fad9-0f7149d2eee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 3.62 KiB | 3.62 MiB/s, done.\n",
            "From https://github.com/atomiiw/neural_speech_decoding\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   4cf685b..d95cb33  main       -> origin/main\n",
            "Updating 4cf685b..d95cb33\n",
            "Fast-forward\n",
            " colab_training.ipynb | 809 \u001b[32m++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
            " 1 file changed, 505 insertions(+), 304 deletions(-)\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"maidouatomwang@gmail.com\"\n",
        "!git config --global user.name \"atomiiw\"\n",
        "!git remote set-url origin https://atomiiw:<TOKEN>@github.com/atomiiw/neural_speech_decoding.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07E6pO5KRoNt",
        "outputId": "4143622f-4004-46ae-ea59-010173f196e8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: TOKEN: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yai__P_TMAl2"
      },
      "source": [
        "## Step 1: Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAhHEVltMAl2",
        "outputId": "2e699055-0bea-4097-e4c3-51eb6fc90781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov  7 02:41:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxXMr4aMAl3"
      },
      "source": [
        "## Step 2: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7H7T8_YMAl3",
        "outputId": "56b8dfc9-b5f4-4a68-9045-49afdbdca6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'neural_speech_decoding' already exists and is not an empty directory.\n",
            "/content/neural_speech_decoding\n",
            "/content/neural_speech_decoding\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo into /content\n",
        "%cd /content\n",
        "!git clone https://github.com/flinkerlab/neural_speech_decoding.git\n",
        "\n",
        "# Enter the repo - this is our workspace\n",
        "%cd neural_speech_decoding\n",
        "\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPw1xRzQMAl3"
      },
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yacs h5py librosa scipy soundfile pesq pystoi tqdm matplotlib seaborn -q"
      ],
      "metadata": {
        "id": "j6gRKLBrMYhS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHPENoCQMAl3"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4nOPRDUMAl3"
      },
      "source": [
        "## Step 4: Mount Google Drive & Setup Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qulz_1fLMAl3",
        "outputId": "a990c857-c6a9-42a4-c3cd-23e296284129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted and linked\n",
            "  Data: example_data/data -> Google Drive\n",
            "  Output: output -> Google Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create persistent storage in Google Drive\n",
        "!mkdir -p /content/drive/MyDrive/nsd_data\n",
        "!mkdir -p /content/drive/MyDrive/nsd_outputs\n",
        "\n",
        "# Link them to the repo workspace\n",
        "!mkdir -p example_data\n",
        "!ln -s /content/drive/MyDrive/nsd_data example_data/data\n",
        "!ln -s /content/drive/MyDrive/nsd_outputs output\n",
        "\n",
        "print(\"✓ Google Drive mounted and linked\")\n",
        "print(f\"  Data: example_data/data -> Google Drive\")\n",
        "print(f\"  Output: output -> Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQp3th7PMAl3"
      },
      "source": [
        "## Step 5: Upload Data to Google Drive\n",
        "\n",
        "**Before running training, you need to:**\n",
        "\n",
        "1. Download HB02 dataset from: https://data.mendeley.com/datasets/fp4bv9gtwk/2\n",
        "2. Upload the files to: **MyDrive/nsd_data/** in your Google Drive\n",
        "3. Verify they're there by running the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmkXvLxjMAl3",
        "outputId": "3cb42aac-667d-4afc-c106-ffcaecb26cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 132M\n",
            "-rw------- 1 root root 132M Nov  7 02:57 HB02.h5\n",
            "\n",
            "If empty, please upload HB02 data to: MyDrive/nsd_data/ in Google Drive\n"
          ]
        }
      ],
      "source": [
        "# Check if data is present\n",
        "!ls -lh /content/drive/MyDrive/nsd_data/\n",
        "\n",
        "# Should see HB02 data files (*.hdf5 or *.h5)\n",
        "print(\"\\nIf empty, please upload HB02 data to: MyDrive/nsd_data/ in Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4MzeDuMAl3"
      },
      "source": [
        "## Step 6: Update Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kB1hxvmMAl3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Update data path in config\n",
        "with open('configs/AllSubjectInfo.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "config['Shared']['RootPath'] = './example_data/data/'\n",
        "\n",
        "with open('configs/AllSubjectInfo.json', 'w') as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "\n",
        "print(f\"✓ Config updated: RootPath = {config['Shared']['RootPath']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRy8us5xMAl3"
      },
      "source": [
        "## Step 7: Stage 1 - Audio-to-Audio Training (a2a)\n",
        "\n",
        "**Time:** ~6 hours on A100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWpZzLjRMAl3"
      },
      "outputs": [],
      "source": [
        "!python train_a2a.py \\\n",
        "  --OUTPUT_DIR output/a2a/HB02 \\\n",
        "  --trainsubject HB02 \\\n",
        "  --testsubject HB02 \\\n",
        "  --param_file configs/a2a_production.yaml \\\n",
        "  --batch_size 16 \\\n",
        "  --reshape 1 \\\n",
        "  --DENSITY \"HB\" \\\n",
        "  --wavebased 1 \\\n",
        "  --n_filter_samples 80 \\\n",
        "  --n_fft 256 \\\n",
        "  --formant_supervision 1 \\\n",
        "  --intensity_thres -1 \\\n",
        "  --epoch_num 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6izAitkqMAl3"
      },
      "outputs": [],
      "source": [
        "# Check Stage 1 completed\n",
        "!ls output/a2a/HB02/*.pth | wc -l\n",
        "print(\"Expected: 60 checkpoint files (model_epoch0.pth to model_epoch59.pth)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuNpS19mMAl3"
      },
      "source": [
        "## Step 8: Stage 2 - ECoG-to-Audio Training (e2a)\n",
        "\n",
        "**Time:** ~10 hours on A100\n",
        "\n",
        "**This produces the weights you need for phoneme classification!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjdpF4fnMAl3"
      },
      "outputs": [],
      "source": [
        "!python train_e2a.py \\\n",
        "  --OUTPUT_DIR output/e2a/resnet_HB02 \\\n",
        "  --trainsubject HB02 \\\n",
        "  --testsubject HB02 \\\n",
        "  --param_file configs/e2a_production.yaml \\\n",
        "  --batch_size 16 \\\n",
        "  --MAPPING_FROM_ECOG ECoGMapping_ResNet \\\n",
        "  --reshape 1 \\\n",
        "  --DENSITY \"HB\" \\\n",
        "  --wavebased 1 \\\n",
        "  --dynamicfiltershape 0 \\\n",
        "  --n_filter_samples 80 \\\n",
        "  --n_fft 256 \\\n",
        "  --formant_supervision 1 \\\n",
        "  --intensity_thres -1 \\\n",
        "  --epoch_num 60 \\\n",
        "  --pretrained_model_dir output/a2a/HB02 \\\n",
        "  --causal 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G906_Q6WMAl4"
      },
      "outputs": [],
      "source": [
        "# Check Stage 2 completed\n",
        "!ls output/e2a/resnet_HB02/*.pth | wc -l\n",
        "!ls -lh output/e2a/resnet_HB02/model_epoch59.pth\n",
        "\n",
        "print(\"\\n✓✓✓ TRAINING COMPLETE ✓✓✓\")\n",
        "print(\"\\nYour pretrained weights:\")\n",
        "print(\"  output/e2a/resnet_HB02/model_epoch59.pth\")\n",
        "print(\"\\nAlso saved to Google Drive:\")\n",
        "print(\"  /content/drive/MyDrive/nsd_outputs/e2a/resnet_HB02/model_epoch59.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT6ahMQtMAl4"
      },
      "source": [
        "## Step 9: Download Weights (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6x1SvlNMAl4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Uncomment to download the final checkpoint to your computer:\n",
        "# files.download('output/e2a/resnet_HB02/model_epoch59.pth')\n",
        "\n",
        "print(\"Weights are in Google Drive at: MyDrive/nsd_outputs/e2a/resnet_HB02/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Ewd032MAl4"
      },
      "source": [
        "## Next Steps: Use for Phoneme Classification\n",
        "\n",
        "Update your `ecog_decoder_finetune.ipynb` with:\n",
        "\n",
        "```python\n",
        "checkpoint_path = \"output/e2a/resnet_HB02/model_epoch59.pth\"\n",
        "# Or from Google Drive:\n",
        "# checkpoint_path = \"/content/drive/MyDrive/nsd_outputs/e2a/resnet_HB02/model_epoch59.pth\"\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}